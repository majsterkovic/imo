{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from random_cycles import gen_random_cycles\n",
    "from local_search import local_search_steepest, local_search_greedy\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid Evolutionary Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_initial_population(data, distance_matrix, size):\n",
    "    start_time = time.time()\n",
    "    population = []\n",
    "    for _ in range(size):\n",
    "        randoms = gen_random_cycles(get_nodes(data))\n",
    "        local_searched = local_search_steepest(*randoms, distance_matrix, data)\n",
    "        population.append(local_searched)\n",
    "    print(\"Initial population generated in: \", time.time() - start_time)\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recombine(parent1, parent2, distance_matrix): # crossing over\n",
    "\n",
    "    edges_in_parent_2 = set()\n",
    "    for c in parent2:\n",
    "        for i in range(len(c)):\n",
    "            edges_in_parent_2.add((c[i], c[(i+1) % len(c)]))\n",
    "\n",
    "    print(\"Krawędzie w parent2: \", edges_in_parent_2)\n",
    "\n",
    "    cycle1 = deepcopy(parent1[0])\n",
    "    cycle2 = deepcopy(parent1[1])\n",
    "\n",
    "    print(\"Długość cyklu 1: \", len(cycle1))\n",
    "    print(\"Długość cyklu 2: \", len(cycle2))\n",
    "    print()\n",
    "\n",
    "    cycle1_marked = [False] * len(cycle1)\n",
    "    cycle2_marked = [False] * len(cycle2)\n",
    "\n",
    "    for i in range(len(cycle1)):\n",
    "        if (cycle1[i], cycle1[(i+1) % len(cycle1)]) in edges_in_parent_2:\n",
    "            cycle1_marked[i] = True\n",
    "            cycle1_marked[(i+1) % len(cycle1)] = True\n",
    "    \n",
    "    for i in range(len(cycle2)):\n",
    "        if (cycle2[i], cycle2[(i+1) % len(cycle2)]) in edges_in_parent_2:\n",
    "            cycle2_marked[i] = True\n",
    "            cycle2_marked[(i+1) % len(cycle2)] = True\n",
    "\n",
    "    free_nodes = []\n",
    "    for i in range(len(cycle1)):\n",
    "        if not cycle1_marked[i]:\n",
    "            free_nodes.append(cycle1[i])\n",
    "    for i in range(len(cycle2)):\n",
    "        if not cycle2_marked[i]:\n",
    "            free_nodes.append(cycle2[i])\n",
    "\n",
    "    # remove False nodes\n",
    "    cycle1 = [cycle1[i] for i in range(len(cycle1)) if cycle1_marked[i]]\n",
    "    cycle2 = [cycle2[i] for i in range(len(cycle2)) if cycle2_marked[i]]\n",
    "\n",
    "    if len(cycle1) == 0 or len(cycle2) == 0:\n",
    "        return parent1[0], parent1[1]\n",
    "\n",
    "    print(\"Po niszczeniu\")\n",
    "    print(\"Długość cyklu 1: \", len(cycle1))\n",
    "    print(\"Długość cyklu 2: \", len(cycle2))\n",
    "    print(\"Długość free_nodes: \", len(free_nodes))\n",
    "    print(\"______\")\n",
    "\n",
    "    while len(free_nodes) > 0:\n",
    "        if len(cycle1) < 100:\n",
    "            best_update1 = float('inf')\n",
    "            best_node1 = None\n",
    "            best_position1 = -1\n",
    "            \n",
    "            for node in free_nodes:\n",
    "                for i in range(len(cycle1)):\n",
    "                    distance_update = distance_matrix[cycle1[i-1]][node] + distance_matrix[node][cycle1[i]] - distance_matrix[cycle1[i-1]][cycle1[i]]\n",
    "                    if distance_update < best_update1:\n",
    "                        best_update1 = distance_update\n",
    "                        best_node1 = node\n",
    "                        best_position1 = i\n",
    "            \n",
    "            if best_node1 is not None:\n",
    "                cycle1.insert(best_position1, best_node1)\n",
    "                free_nodes.remove(best_node1)\n",
    "\n",
    "        if len(cycle2) < 100:\n",
    "            best_update2 = float('inf')\n",
    "            best_node2 = None\n",
    "            best_position2 = -1\n",
    "            \n",
    "            for node in free_nodes:\n",
    "                for i in range(len(cycle2)):\n",
    "                    distance_update = distance_matrix[cycle2[i-1]][node] + distance_matrix[node][cycle2[i]] - distance_matrix[cycle2[i-1]][cycle2[i]]\n",
    "                    if distance_update < best_update2:\n",
    "                        best_update2 = distance_update\n",
    "                        best_node2 = node\n",
    "                        best_position2 = i\n",
    "            \n",
    "            if best_node2 is not None:\n",
    "                cycle2.insert(best_position2, best_node2)\n",
    "                free_nodes.remove(best_node2)\n",
    "\n",
    "    print(\"Po odbudowie\")\n",
    "    print(\"Długość cyklu 1: \", len(cycle1))\n",
    "    print(\"Długość cyklu 2: \", len(cycle2))\n",
    "    print(\"Długość free_nodes: \", len(free_nodes))\n",
    "    print(\"______\")\n",
    "\n",
    "    return cycle1, cycle2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_evolutionary_algorithm(distance_matrix, data, population_size, num_generations, local=False):\n",
    "    population = gen_initial_population(data, distance_matrix, population_size)\n",
    "    \n",
    "    for _ in range(num_generations):\n",
    "        \n",
    "        parent_indices = np.random.choice(len(population), 2, replace=False)\n",
    "        parent1, parent2 = population[parent_indices[0]], population[parent_indices[1]]\n",
    "                \n",
    "        offspring = recombine(parent1, parent2, distance_matrix)\n",
    "        if local:\n",
    "            offspring = local_search_steepest(*offspring, distance_matrix, data)\n",
    "        \n",
    "        worst_index = np.argmax([calculate_cycles_length(*ind, distance_matrix) for ind in population])\n",
    "        worst_length = calculate_cycles_length(*population[worst_index], distance_matrix)\n",
    "\n",
    "        offspring_length = calculate_cycles_length(*offspring, distance_matrix)\n",
    "        \n",
    "        if offspring_length < worst_length and is_diverse(offspring, population, distance_matrix):\n",
    "            population[worst_index] = offspring\n",
    "    \n",
    "    best_index = np.argmin([calculate_cycles_length(*ind, distance_matrix) for ind in population])\n",
    "    return population[best_index]\n",
    "\n",
    "\n",
    "\n",
    "def is_diverse(individual, population,  distance_matrix, threshold=0.1):\n",
    "    individual_length = calculate_cycles_length(*individual, distance_matrix)\n",
    "    for other in population:\n",
    "        other_length = calculate_cycles_length(*other, distance_matrix)\n",
    "        if abs(individual_length - other_length) < threshold * individual_length:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "lengths = []\n",
    "cycles = []\n",
    "\n",
    "\n",
    "for filename in ['data/kroB200.tsp', 'data/kroA200.tsp']:\n",
    "\n",
    "    file = filename.split('/')[-1]\n",
    "    data = read_data_file(filename)\n",
    "    distance_matrix = calculate_distance_matrix(data)\n",
    "\n",
    "    for i in range(10):\n",
    "        for local in [True, False]:\n",
    "            print(f\"Processing: {i} {local} {filename}\")\n",
    "            start = time.time()\n",
    "\n",
    "            cycle1, cycle2 = hybrid_evolutionary_algorithm(\n",
    "                distance_matrix,\n",
    "                data,\n",
    "                21,\n",
    "                100,\n",
    "                local=local)\n",
    "            \n",
    "            time_taken = time.time() - start\n",
    "            length = calculate_cycles_length(cycle1, cycle2, distance_matrix)\n",
    "\n",
    "            times.append((file, local, time_taken))\n",
    "            lengths.append((file, local, length))\n",
    "            cycles.append((file, local, cycle1, cycle2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = pd.DataFrame(times, columns=[\"Instance\", \"Method\", \"Time\"])\n",
    "times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_df = pd.DataFrame(lengths, columns=[\"Instance\", \"Method\", \"Length\"])\n",
    "lengths_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grupowanie danych i obliczanie statystyk\n",
    "time_stats = times_df.groupby([\"Instance\", \"Method\"])[\"Time\"].agg(['min', 'mean', 'max']).reset_index()\n",
    "length_stats = lengths_df.groupby([\"Instance\", \"Method\"])[\"Length\"].agg(['min', 'mean', 'max']).reset_index()\n",
    "\n",
    "# Łączenie statystyk w jeden DataFrame\n",
    "stats_df = pd.merge(time_stats, length_stats, on=[\"Instance\", \"Method\"], suffixes=(\"_time\", \"_length\"))\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles_df = pd.DataFrame(cycles, columns=[\"Instance\", \"Method\", \"Cycle1\", \"Cycle2\"])\n",
    "def calculate_length(row):\n",
    "    data = read_data_file(\"data/\" + row['Instance'])\n",
    "    distance_matrix = calculate_distance_matrix(data)\n",
    "    return calculate_cycles_length(row['Cycle1'], row['Cycle2'], distance_matrix)\n",
    "\n",
    "cycles_df = pd.DataFrame(cycles, columns=[\"Instance\", \"Method\", \"Cycle1\", \"Cycle2\"])\n",
    "cycles_df['Cycle_Length'] = cycles_df.apply(calculate_length, axis=1)\n",
    "cycles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Instance' and 'Method' and find the index of the minimum 'Cycle_Length'\n",
    "min_cycle_indices = cycles_df.groupby(['Instance', 'Method'])['Cycle_Length'].idxmin()\n",
    "\n",
    "# Use the indices to get the rows with the minimum 'Cycle_Length'\n",
    "min_cycles_df = cycles_df.loc[min_cycle_indices]\n",
    "\n",
    "min_cycles_df\n",
    "\n",
    "# if dir plots does not exist create it\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "\n",
    "for i, row in min_cycles_df.iterrows():\n",
    "    plot_cycles(row['Cycle1'], row['Cycle2'], read_data_file(\"data/\" + row['Instance']), f\"plots/plot_{row['Instance'].replace('/', '')}_{row['Method']}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
