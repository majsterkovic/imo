{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local_search import local_search_greedy\n",
    "from ILS2 import *\n",
    "from random_cycles import gen_random_cycles\n",
    "import numpy as np\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from calc import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAMES = [\"kroB200.tsp\"]\n",
    "ILS2a_TIME = 250\n",
    "CYCLES_SET_SIZE = 50\n",
    "\n",
    "results = []\n",
    "\n",
    "for filename in FILENAMES:\n",
    "    print(f\"Obliczenia dla pliku {filename}\")\n",
    "    data = read_data_file(\"data/\" + filename)\n",
    "    dist_matrix = calculate_distance_matrix(data)\n",
    "\n",
    "    pickle_file = 'cycles_' + filename + '.pkl'\n",
    "\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            cycles = pickle.load(f)\n",
    "    except:\n",
    "        print(\"Brak pliku z cyklami\")\n",
    "\n",
    "    c = {}\n",
    "\n",
    "    for i in tqdm(range(len(cycles))):\n",
    "        cycle1a, cycle2a = cycles[i]\n",
    "        cycle1b, cycle2b = cycles[(i+1) % len(cycles)]\n",
    "\n",
    "        common = get_common_edges(cycle1a, cycle2a, cycle1b, cycle2b)\n",
    "        for edge in common:\n",
    "            if edge not in c:\n",
    "                c[edge] = common[edge]\n",
    "            else:\n",
    "                c[edge] += common[edge]\n",
    "        \n",
    "    print(\"Wspólne krawędzie policzone\")\n",
    "    # sort by common edges\n",
    "    c = dict(sorted(c.items(), key=lambda item: item[1], reverse=True))\n",
    "    c_df = pd.DataFrame(c.items(), columns=['edge', 'common'])\n",
    "    c_df[\"length\"] = c_df[\"edge\"].apply(lambda x: dist_matrix[x[0]][x[1]])\n",
    "    #len_025 = c_df[\"length\"].quantile(0.25)\n",
    "    c_df = c_df.head(int(len(c_df) * 0.08))\n",
    "    #c_df = c_df[c_df[\"length\"] <= len_025]\n",
    "    c_df[\"a_x\"] = c_df[\"edge\"].apply(lambda x: data[x[0]][0])\n",
    "    c_df[\"a_y\"] = c_df[\"edge\"].apply(lambda x: data[x[0]][1])\n",
    "    c_df[\"b_x\"] = c_df[\"edge\"].apply(lambda x: data[x[1]][0])\n",
    "    c_df[\"b_y\"] = c_df[\"edge\"].apply(lambda x: data[x[1]][1])\n",
    "\n",
    "    # posortuj krawędzie po pierwszej współrzędnej pierwszego wierzchołka\n",
    "    c_df = c_df.sort_values(by=['a_x'])\n",
    "\n",
    "    # dodaj pierwszą połowę krawędzi do cyklu 1 i drugą do cyklu 2\n",
    "    cycle1 = []\n",
    "    cycle2 = []\n",
    "\n",
    "    len_df = len(c_df)\n",
    "    for i in range(len(c_df)):\n",
    "        a,b = [c_df.iloc[i][\"edge\"][0], c_df.iloc[i][\"edge\"][1]]\n",
    "        if i < len_df / 2:\n",
    "            if a not in cycle1 and b not in cycle1:\n",
    "                cycle1.append(a)\n",
    "                cycle1.append(b)\n",
    "        else:\n",
    "            if a not in cycle2 and b not in cycle2 and a not in cycle1 and b not in cycle1:\n",
    "                cycle2.append(a)\n",
    "                cycle2.append(b)\n",
    "\n",
    "\n",
    "    free_nodes = list(set(get_nodes(data)) - set(cycle1) - set(cycle2))\n",
    "\n",
    "    while len(cycle1) < 100:\n",
    "        best_update1 = float('inf')\n",
    "        best_node1 = None\n",
    "        best_position1 = -1\n",
    "\n",
    "        for node in free_nodes:\n",
    "            for i in range(len(cycle1)):\n",
    "                distance_update = dist_matrix[cycle1[i-1]][node] + dist_matrix[node][cycle1[i]] - dist_matrix[cycle1[i-1]][cycle1[i]]\n",
    "                if distance_update < best_update1:\n",
    "                    best_update1 = distance_update\n",
    "                    best_node1 = node\n",
    "                    best_position1 = i\n",
    "\n",
    "        if best_node1 is not None:\n",
    "            cycle1.insert(best_position1, best_node1)\n",
    "            free_nodes.remove(best_node1)\n",
    "\n",
    "\n",
    "    while len(free_nodes) > 0:\n",
    "        best_update2 = float('inf')\n",
    "        best_node2 = None\n",
    "        best_position2 = -1\n",
    "\n",
    "        for node in free_nodes:\n",
    "            for i in range(len(cycle2)):\n",
    "                distance_update = dist_matrix[cycle2[i-1]][node] + dist_matrix[node][cycle2[i]] - dist_matrix[cycle2[i-1]][cycle2[i]]\n",
    "                if distance_update < best_update2:\n",
    "                    best_update2 = distance_update\n",
    "                    best_node2 = node\n",
    "                    best_position2 = i\n",
    "\n",
    "        if best_node2 is not None:\n",
    "            cycle2.insert(best_position2, best_node2)\n",
    "            free_nodes.remove(best_node2)\n",
    "\n",
    "    starting1 = deepcopy(cycle1)\n",
    "    starting2 = deepcopy(cycle2)\n",
    "\n",
    "    \n",
    "    for _ in tqdm(range(1)):\n",
    "        s = time.time()\n",
    "        cycle1 = deepcopy(starting1)\n",
    "        cycle2 = deepcopy(starting2)\n",
    "\n",
    "        time_elapsed = 30\n",
    "        no_improvement = 0\n",
    "        size = 0.1\n",
    "        best_length = calculate_cycles_length(cycle1, cycle2, dist_matrix)\n",
    "\n",
    "        while time_elapsed > 0:\n",
    "            start_time = time.time()\n",
    "            c1, c2 = severe_perturbation(starting1, starting2, dist_matrix, size=size)\n",
    "            length = calculate_cycles_length(c1, c2, dist_matrix)\n",
    "            if length < best_length:\n",
    "                best_length = length\n",
    "                cycle1 = c1\n",
    "                cycle2 = c2\n",
    "            else:\n",
    "                no_improvement += 1\n",
    "     \n",
    "                if no_improvement >= 6:\n",
    "                    cycle2, cycle2 = local_search_steepest(cycle1, cycle2, dist_matrix, data)\n",
    "             \n",
    "                    no_improvement = 0\n",
    "            \n",
    "            stop_time = time.time()\n",
    "            time_elapsed = time_elapsed - (stop_time - start_time)\n",
    "\n",
    "        e = time.time()\n",
    "        results.append((filename, cycle1, cycle2, calculate_cycles_length(cycle1, cycle2, dist_matrix), e-s))\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"filename\", \"cycle1\", \"cycle2\", \"length\", \"time\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grupowanie danych i obliczanie statystyk\n",
    "time_stats = results_df.groupby([\"filename\"])[\"time\"].agg(['min', 'mean', 'max']).reset_index()\n",
    "length_stats = results_df.groupby([\"filename\"])[\"length\"].agg(['min', 'mean', 'max']).reset_index()\n",
    "\n",
    "# Łączenie statystyk w jeden DataFrame\n",
    "stats_df = pd.merge(time_stats, length_stats, on=[\"filename\"], suffixes=(\"_time\", \"_length\"))\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot best cycles\n",
    "results_df = results_df.sort_values(by=[\"filename\", \"length\"])\n",
    "best_cycles = results_df[\"cycle1\"].iloc[0], results_df[\"cycle2\"].iloc[0]\n",
    "\n",
    "plot_cycles(*best_cycles, data, \"Best cycles\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
